{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIZyoIQx3iir"
      },
      "source": [
        "##Anjali Kumari\n",
        "\n",
        "##25/AFI/17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJyQfuI6OkZW"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio pandas scikit-learn tqdm -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfL8Dr1rOr2N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmnfIJppOrz9",
        "outputId": "3a4bb159-c797-4528-c370-87cea415ef68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TwtLlaMOrxl",
        "outputId": "4299a165-7fab-4ef8-e075-9152c17fd3f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 118964\n",
            "Sample: ['Go.\\tVe.', 'Go.\\tVete.', 'Go.\\tVaya.']\n"
          ]
        }
      ],
      "source": [
        "file_path = \"spa.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    texts = f.readlines()\n",
        "\n",
        "texts = [t.strip() for t in texts if t.strip()]\n",
        "\n",
        "print(\"Total samples:\", len(texts))\n",
        "print(\"Sample:\", texts[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrQ18b8WOrvF",
        "outputId": "105dd7e1-5178-404f-d8a0-337d8bb95b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80000 10000 10000\n"
          ]
        }
      ],
      "source": [
        "train_texts = texts[:80000]\n",
        "val_texts = texts[80000:90000]\n",
        "test_texts = texts[90000:100000]\n",
        "\n",
        "print(len(train_texts), len(val_texts), len(test_texts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNK2fjzPOrs9",
        "outputId": "47081e3b-7862-40cb-f024-a3dd915ba797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 43556\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "for text in train_texts:\n",
        "    counter.update(tokenize(text))\n",
        "\n",
        "vocab = {word: i+2 for i, (word, _) in enumerate(counter.most_common())}\n",
        "vocab[\"<PAD>\"] = 0\n",
        "vocab[\"<UNK>\"] = 1\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocab size:\", vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfJZqMTDOrqd"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 20\n",
        "\n",
        "def encode(text):\n",
        "    tokens = tokenize(text)\n",
        "    ids = [vocab.get(tok, 1) for tok in tokens][:MAX_LEN]\n",
        "    if len(ids) < MAX_LEN:\n",
        "        ids += [0] * (MAX_LEN - len(ids))\n",
        "    return ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpcmlhcsOroN"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.data = [encode(t) for t in texts]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx][:-1])\n",
        "        y = torch.tensor(self.data[idx][1:])\n",
        "        return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZxqZOdUOrl1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(TextDataset(train_texts), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TextDataset(val_texts), batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(TextDataset(test_texts), batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFJd3xD5Orjd",
        "outputId": "3ac4ba14-a43f-4e23-c2c8-76114a186dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTMModel(\n",
            "  (embedding): Embedding(43556, 128)\n",
            "  (lstm): LSTM(128, 256, batch_first=True)\n",
            "  (fc): Linear(in_features=256, out_features=43556, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = LSTMModel(vocab_size).to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4H810YXO7C9"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwUz22iOO7At",
        "outputId": "2fb3d009-8d71-4ae2-94a3-b7bae03bc54d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:41<00:00, 14.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 6.9466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:43<00:00, 14.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 5.1664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 4.2719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:44<00:00, 13.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 3.6771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 3.2332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 2.8863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:44<00:00, 13.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 2.6158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 2.4053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 2.2405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 2.1066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss: 1.9951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss: 1.9022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss: 1.8215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss: 1.7519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss: 1.6907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss: 1.6368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss: 1.5885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss: 1.5458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss: 1.5072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:45<00:00, 13.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Loss: 1.4720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "\n",
        "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Bk-ZU7O6-d",
        "outputId": "cf2f58ad-2d05-4e9c-beb6-283bd7a26f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 5.503110586842404\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "val_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
        "        val_loss += loss.item()\n",
        "\n",
        "print(\"Validation Loss:\", val_loss / len(val_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXLLDYKAO68N",
        "outputId": "c0e050d3-d1c5-44c5-b89d-80d79643dd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 6.118708459636833\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
        "        test_loss += loss.item()\n",
        "\n",
        "print(\"Test Loss:\", test_loss / len(test_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnIjfkLVOrhF",
        "outputId": "9af65589-f881-4722-b7d2-be2da6e403ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is a very of me. fish. two. his. his. his. his. error error error error así así así así\n"
          ]
        }
      ],
      "source": [
        "def predict_next(text):\n",
        "    model.eval()\n",
        "    encoded = torch.tensor([encode(text)[:-1]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(encoded)\n",
        "        pred = output.argmax(dim=-1)\n",
        "\n",
        "    inv_vocab = {v: k for k, v in vocab.items()}\n",
        "    words = [inv_vocab.get(i.item(), \"<UNK>\") for i in pred[0]]\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(predict_next(\"this is a simple\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3VNqQlSTtg4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
